#!/usr/bin/env python
import argparse # optparse is deprecated
from itertools import islice # slicing for iterators
import re
from collections import Counter
from nltk.stem.lancaster import *

function_words = ["you", "i", "to", "the", "a", "and", "that", "it", "of", "me", "what", "is", "in", "this", "know",  "for", "no", "have", "my", "don", "just", "not", "do", "be", "on", "your", "was", "we", "with", "so", "but", "all", "well", "are", "he", "oh", "about", "right", "d", "ll", "ve", "m", "s", "t"]

stemmer = LancasterStemmer()
C_function = Counter(function_words)
for item in C_function.keys():
	C_function[item] = 10

def har_mean(p, r, a):
	den = (a * p + (1 - a) * r)
	if den == 0: return 0.0
	return p * r / den

def meteor(h, ref, alpha, delta):
	#shared function words
	m_function = float(sum((Counter(h) & Counter(ref) & C_function).viewvalues()))
	#shared content words
	#m_content = float(-1.0*levenshtein(h,ref)) - m_function
	m_content = float(sum((Counter(h) & Counter(ref)).viewvalues())) - m_function
	if not h:
		p = 0.0
	else:
		p = ((delta * m_content) + ((1 - delta) * m_function)) / len(h)
	if not ref:
		r = 0.0
	else:
		r = ((delta * m_content) + ((1 - delta) * m_function)) / len(ref)
	return har_mean(p,r,alpha)
 
def main():
	parser = argparse.ArgumentParser(description='Evaluate translation hypotheses.')
	# PEP8: use ' and not " for strings
	parser.add_argument('-i', '--input', default='data/train-test.hyp1-hyp2-ref',
			help='input file (default data/train-test.hyp1-hyp2-ref)')
	parser.add_argument('-n', '--num_sentences', default=None, type=int,
			help='Number of hypothesis pairs to evaluate')
	parser.add_argument('-a', '--alpha', default=0.5, type=float, help='precision/recall weight parameter')
	parser.add_argument('-d', '--delta', default=0.5, type=float, help='content/function word weight parameter')
	opts = parser.parse_args()
 
	def sentences():
		with open(opts.input) as f:
			for pair in f:
		#fixed preprocessing to remove punctuation and make lowercase
				yield [re.findall(r"[\w]+",sentence) for sentence in re.sub("\/"," ",re.sub("&quot;","",pair.lower().strip())).decode('unicode_escape').encode('ascii','ignore').split(' ||| ')]
	# note: the -n option does not work in the original code
	for h1, h2, ref in islice(sentences(), opts.num_sentences):
		hyp1 = []
		hyp2 = []
		reference = []
		for h in h1:
			hyp1.append(stemmer.stem(h))
		for h in h2:
			hyp2.append(stemmer.stem(h))
		for r in ref:
			reference.append(stemmer.stem(r))
		h1_val = meteor(hyp1, reference, opts.alpha, opts.delta)
		h2_val = meteor(hyp2, reference, opts.alpha, opts.delta)
	
		if h1_val != 0 and h2_val != 0:
			if (h1_val / h2_val) > 1.0002:
				print -1
			elif (h1_val / h2_val) <= 1.0002 and (h1_val / h2_val) >= 0.9998:
				print 0
			else:
				print 1
		elif h2_val == 0:
			print -1
		else:
			print 1
	 
# convention to allow import of this file as a module
if __name__ == '__main__':
	main()
